{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">Assignment 1: Estimation Theory, Fisher Information, CRLB</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This material, no matter whether in printed or electronic form, may be used for personal and non-commercial educational use only. Any reproduction of this material, no matter whether as a whole or in parts, no matter whether in printed or in electronic form, requires explicit prior acceptance of the authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start with some preliminary facts and intuition on why it is often a good idea to use the logarithm in optimization tasks, like parameter estimation:\n",
    "\n",
    "* log is strictly monotonically increasing, so log likelihood is a strictly monotonically increasing transformation of likelihood and maxima occur at same parameter values\n",
    "    * $p(x;\\theta_1) > p(x;\\theta_2) \\Leftrightarrow \\ln p(x;\\theta_1) > \\ln p(x;\\theta_2)$\n",
    "    * $\\textrm{argmax}_\\theta\\ p(x;\\theta) = \\textrm{argmax}_\\theta \\ln p(x;\\theta)$    \n",
    "* products become sums\n",
    "    * $L = p_1 p_2 p_3$\n",
    "    * $\\ln(L) = \\ln(p_1) + \\ln(p_2) + \\ln(p_3)$\n",
    "* derivatives are easier\n",
    "    * $\\frac{\\partial L}{\\partial \\theta} = \n",
    "    \\frac{\\partial p_1}{\\partial \\theta} p_2 p_3 +\n",
    "    p_1 \\frac{\\partial p_2}{\\partial \\theta} p_3 +\n",
    "    p_1 p_2 \\frac{\\partial p_3}{\\partial \\theta}\n",
    "    $\n",
    "    * $\\frac{\\partial \\ln(L)}{\\partial \\theta} = \n",
    "    \\frac{\\partial \\ln(p_1)}{\\partial \\theta} +\n",
    "    \\frac{\\partial \\ln(p_2)}{\\partial \\theta} + \n",
    "    \\frac{\\partial \\ln(p_3)}{\\partial \\theta}$\n",
    "* likelihoods become very small and consequently they run out of floating point precision very quickly\n",
    "    * log likelihoods are numerically more stable\n",
    "* for some distributions the log space avoids expansive computation\n",
    "    * exp in gaussian pdf:\n",
    "        * $p(x; \\theta) = \\frac{1}{(\\sqrt{2\\pi})^{d}\\sqrt{det \\Sigma}}\\,\\exp^{-\\frac{1}{2}(x-\\mu)^{T}\\Sigma^{-1}(x-\\mu)}$\n",
    "    * no exp in log space:\n",
    "        * $\\ln p(x; \\theta) = -\\frac{d}{2}\\ln(2\\pi) -\\frac{1}{2}\\ln(\\textrm{det} \\Sigma) - \\frac{1}{2}(x-\\mu)^{T}\\Sigma^{-1}(x-\\mu)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also briefly visualize the situation with a plot of the log-likelihood vs. the actual likelihood. You should see that the logarithm is just a monotonic function, so it doesn't change the actual optimization problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of likelihood vs. log-likelihood\n",
    "\n",
    "L = np.linspace(0.001,5,1000)\n",
    "L_ln = np.log(L)\n",
    "\n",
    "fig = plt.figure(figsize=(16,16))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(L, L_ln, label='ln(L)')\n",
    "plt.xlabel('Likelihood L')\n",
    "plt.ylabel('log-Likelihood ln(L)')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(\"ln(L) vs L\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a sequence of independent and identically distributed (i.i.d.) random variables $x_{1}, x_{2},...,x_{n}$ that are sampled from a normal distribution with an unknown expectation parameter $\\mu$ and a known standard deviation parameter $\\sigma$, i.e.\n",
    "$x_{i}$ are distributed according to the density function\n",
    "\n",
    "$$\n",
    "p(x;\\mu,\\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\, \\text{exp}^{-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}}\n",
    "$$\n",
    "\n",
    "Let us start this task by creating 3 normally distributed datasets with same $\\mu = 5$ but different $\\sigma = 1,3,10$.\n",
    "We also want to visualize their histograms and compare with the actual densities. The procedure should be clearly visible from the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_function(x, mu, sigma):\n",
    "    \"\"\" This is the 1D gaussian probability density function with mean mu and standard deviation sigma \"\"\"\n",
    "    \n",
    "    return 1/(sigma*np.sqrt(2*np.pi))*np.exp(-(x-mu)**2/(2*sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(mu, sigma, samples):\n",
    "    \"\"\" This funtion generates the data \"\"\"\n",
    "    \n",
    "    x = np.linspace(-15,25,samples)\n",
    "    \n",
    "    # get density over x\n",
    "    density = gauss_function(x, mu, sigma)\n",
    "    \n",
    "    # sample for the gaussian distribution\n",
    "    X_samples = sigma*np.random.randn(samples) + mu\n",
    "    \n",
    "    return x, density, X_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we generate 3 datasets with 500 samples each with same mu = 5 but different sigmas = 1,3,10\n",
    "\n",
    "n = 500\n",
    "mu = 5.0\n",
    "sigma_1 = 1.0\n",
    "sigma_2 = 3.0\n",
    "sigma_3 = 10.0\n",
    "\n",
    "x, p1, X1 = generate_data(mu, sigma_1, samples=n)\n",
    "_, p2, X2 = generate_data(mu, sigma_2, samples=n)\n",
    "_, p3, X3 = generate_data(mu, sigma_3, samples=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is only for plotting\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(x, p1, label='p1', color='r')\n",
    "plt.plot(X1, np.repeat(-0.1, len(x)), 'ro', label='X1 samples')\n",
    "plt.plot(x, p2, label='p2', color='g')\n",
    "plt.plot(X2, np.repeat(-0.2, len(x)), 'go', label='X2 samples')\n",
    "plt.plot(x, p3, label='p3', color='b')\n",
    "plt.plot(X3, np.repeat(-0.3, len(x)), 'bo', label='X3 samples')\n",
    "plt.axis([-15, 25, -0.4, 1.0])\n",
    "plt.grid()\n",
    "plt.title('Gauss density functions and samples')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "\n",
    "# the histogram of the data\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "n, bins, patches = plt.hist(X1, density=True, facecolor='r', alpha=0.75, label='X1 samples')\n",
    "plt.plot(x, p1, label='p1', color='r')\n",
    "n, bins, patches = plt.hist(X2, density=True, facecolor='g', alpha=0.75, label='X2 samples')\n",
    "plt.plot(x, p2, label='p2', color='g')\n",
    "n, bins, patches = plt.hist(X3, density=True, facecolor='b', alpha=0.75, label='X3 samples')\n",
    "plt.plot(x, p3, label='p3', color='b')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Gauss density and histogram of samples')\n",
    "plt.text(-3.6, 0.9, r'$\\mu=5,\\ \\sigma=1,2,4$')\n",
    "plt.axis([-15, 25, -0.4, 1.0])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to work with the likelihood and log-likelihood of the previously created data. To this end, recall the following definitions:\n",
    "\n",
    "**Likelihood:**\n",
    "$$\\mathcal{L}(w) = \\prod_{i=1}^n p(x_i ; w)$$\n",
    "\n",
    "**Log-Likelihood:**\n",
    "$$\\ln\\mathcal{L}(w) = \\sum_{i=1}^n \\ln p(x_i ; w)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(208,90,80)\">Exercise 1 (10 points)</h3>\n",
    "\n",
    "As a first task, implement the log-likelihood function for a given dataset, a given $\\mu$ and a given $\\sigma$, using the previously implemented functions. Test your function by executing the print commands below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the log-likehood function; it should return a scalar value\n",
    "\n",
    "def log_likelihood(data, mu, sigma):\n",
    "    \"\"\" Calculates the log likelihood\"\"\"\n",
    "    \n",
    "    ########## YOUR SOLUTION HERE ##########\n",
    "        \n",
    "    return lnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ln(L)(X1,mu=5,sigma1) = %8.1f\" % log_likelihood(X1, mu=5, sigma=sigma_1))\n",
    "print(\"ln(L)(X1,mu=5,sigma2) = %8.1f\" % log_likelihood(X1, mu=5, sigma=sigma_2))\n",
    "print(\"ln(L)(X1,mu=5,sigma3) = %8.1f\" % log_likelihood(X1, mu=5, sigma=sigma_3))\n",
    "print(\"\\n\")\n",
    "print(\"ln(L)(X2,mu=5,sigma1) = %8.1f\" % log_likelihood(X2, mu=5, sigma=sigma_1))\n",
    "print(\"ln(L)(X2,mu=5,sigma2) = %8.1f\" % log_likelihood(X2, mu=5, sigma=sigma_2))\n",
    "print(\"ln(L)(X2,mu=5,sigma3) = %8.1f\" % log_likelihood(X2, mu=5, sigma=sigma_3))\n",
    "print(\"\\n\")\n",
    "print(\"ln(L)(X3,mu=5,sigma1) = %8.1f\" % log_likelihood(X3, mu=5, sigma=sigma_1))\n",
    "print(\"ln(L)(X3,mu=5,sigma2) = %8.1f\" % log_likelihood(X3, mu=5, sigma=sigma_2))\n",
    "print(\"ln(L)(X3,mu=5,sigma3) = %8.1f\" % log_likelihood(X3, mu=5, sigma=sigma_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to see that the log-likelihood for data set $X_i$ is largest for $\\sigma_i$.\n",
    "\n",
    "Now let us gain some intuition on how the log-likelihood function behaves, if data and $\\sigma$ are given, but $\\mu$ varies in the set $[-5,15]$. \n",
    "\n",
    "<h3 style=\"color:rgb(0,120,170)\">Exercise 2 (20 Points)</h3>\n",
    "\n",
    "Your task is to complete the implementation of the function `calculate_log_likelihood_over_mu` so that it outputs the list `mu_set` (which has already been created) and an array `lnL_array`. This array should contain the log-likelihoods calculated from data set $X$, $\\sigma$ and $\\mu_i$. Afterwards, compute the estimators $\\hat{\\mu}$ (argmax) and execute the plotting routine for the different values of $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_likelihood_over_mu(data, sigma):\n",
    "    \n",
    "    mu_set = np.linspace(-5,15,501)\n",
    "    lnL_list = []\n",
    "\n",
    "    ########## YOUR SOLUTION HERE ##########\n",
    "    \n",
    "    lnL_array = np.array(lnL_list)\n",
    "    return mu_set, lnL_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_set, lnL_array1 = calculate_log_likelihood_over_mu(X1, sigma_1)\n",
    "_, lnL_array2 = calculate_log_likelihood_over_mu(X2, sigma_2)\n",
    "_, lnL_array3 = calculate_log_likelihood_over_mu(X3, sigma_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mu-hat = argmax_mu(lnL(X1,mu,sigma1)): %4.2f\" % mu_set[np.argmax(lnL_array1)])\n",
    "print(\"mu-hat = argmax_mu(lnL(X2,mu,sigma2)): %4.2f\" % mu_set[np.argmax(lnL_array2)])\n",
    "print(\"mu-hat = argmax_mu(lnL(X3,mu,sigma3)): %4.2f\" % mu_set[np.argmax(lnL_array3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mu_set, lnL_array1, label='ln L1', color='r')\n",
    "plt.plot(mu_set, lnL_array2, label='ln L2', color='g')\n",
    "plt.plot(mu_set, lnL_array3, label='ln L3', color='b')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(\"ln(L) vs $\\mu$\")\n",
    "plt.ylabel(\"ln(L)\")\n",
    "plt.xlabel('$\\mu$')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is likely that the estimator $\\hat{\\mu}$ is closest to the true value $\\mu = 5$ for $\\sigma_1$ and deviates most for $\\sigma_3$.\n",
    "\n",
    "Run all cells again several times (including new random data from the fixed probability distribution) to get a feeling for the statistics.\n",
    "\n",
    "<h3 style=\"color:rgb(0,120,170)\">Exercise 3 (30 Points)</h3>\n",
    "\n",
    "In the previous tasks you should have gained some intuition on how the variance of an unbiased estimator for $\\mu$ behaves in certain situations (i.e. for different $\\sigma$. Now we want to confirm these observations with a rigorous calculation on the lower bound of this variance:\n",
    "\n",
    "* Determine/Calculate the Cramer-Rao lower bound for the variance of an unbiased estimator for the parameter $\\mu$ for the situation described at the beginning of task 1.\n",
    "\n",
    "To do this, work through the following steps:\n",
    "\n",
    "1. Using (25), calculate the Log-Likelihood with the probability density function $p(x;\\mu,\\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\, \\text{exp}^{-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}}$ for $n$ data samples.\n",
    "2. Verify equation (27) on slide 17 for this situation to simplify the calculation of $\\mathbf{I}_{F}(\\mu)$.\n",
    "3. Use the simplified (curvature) formula (31) to calculate $\\mathbf{I}_{F}(\\mu)$. In our case, it will be a scalar $I_F$ as the parameter is also a scalar.\n",
    "4. Calculate the $\\text{CRLB}$ from the result of step 3\n",
    "\n",
    "If you did everything right, you should end up with $\\text{CRLB} = \\frac{\\sigma^2}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">Exercise 4 (5 Points)</h3>\n",
    "\n",
    "Now you are asked to implement the result of the previous task, i.e. provide a function that outputs the Fisher information for a given number $n$ of data samples and $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_information_mu(n, sigma):\n",
    "    \"\"\" Calculate the fisher information  \"\"\"\n",
    "    \n",
    "    ########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IF(mu) with sigma1: IF = %6.2f\" %fisher_information_mu(n=500,sigma=sigma_1))\n",
    "print(\"IF(mu) with sigma2: IF = %6.2f\" %fisher_information_mu(n=500,sigma=sigma_2))\n",
    "print(\"IF(mu) with sigma3: IF = %6.2f\" %fisher_information_mu(n=500,sigma=sigma_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">Exercise 5 (5 Points)</h3>\n",
    "\n",
    "Answer some questions on your observations (2 sentences in total are enough):\n",
    "* How does the variance of the estimator of the mean $\\mu$ depend on standard deviation $\\sigma$ and sample number $n$?\n",
    "* Which values of $\\sigma$ are better for estimating $\\mu$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to prove some basic properties of the arithmetic mean as an estimator for the mean of the sample given in task 1.\n",
    "\n",
    "<h3 style=\"color:rgb(0,120,170)\">Exercise 6 (15 Points)</h3>\n",
    "\n",
    "Consider the estimator $\\hat\\mu = \\sum_{i=1}^{n} \\frac{1}{n} x_{i}$ i.e. the aritmetic mean of the observations. Show that this is an unbiased estimator for the parameter $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">Exercise 7 (15 Points)</h3>\n",
    "\n",
    "Check if the estimator $\\hat\\mu = \\frac{1}{n} \\sum_{i}^{n} x_{i}$ is efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
