{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "id": "29F82rscO0pY",
        "pycharm": {
          "name": "#%% raw\n"
        }
      },
      "source": [
        "\n",
        "This  material,  no  matter  whether  in  printed  or  electronic  form, may  be  used  for  personal  and non-commercial educational use only. Any reproduction of this manuscript, no matter whether as a whole or in parts, no matter whether in printed or in electronic form,\n",
        "requires explicit prior acceptance of the authors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "H-U4oTvvO0pZ",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "36819a87118b39ea83154056007f8ede",
          "grade": false,
          "grade_id": "cell-0be15f53f67530c6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "<!-- Assignment 2 - SS 2023 -->\n",
        "\n",
        "# Vision Networks and Fast Training (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYOPiLEhO0pe"
      },
      "source": [
        "This notebook contains one of the assignments for the exercises in Deep Learning and Neural Nets 2.\n",
        "It provides a skeleton, i.e. code with gaps, that will be filled out by you in different exercises.\n",
        "All exercise descriptions are visually annotated by a vertical bar on the left and some extra indentation,\n",
        "unless you already messed with your jupyter notebook configuration.\n",
        "Any questions that are not part of the exercise statement do not need to be answered,\n",
        "but should rather be interpreted as triggers to guide your thought process.\n",
        "\n",
        "**Note**: The cells in the introductory part (before the first subtitle)\n",
        "perform all necessary imports and provide utility functions that should work without (too much) problems.\n",
        "Please, do not alter this code or add extra import statements in your submission, unless explicitly allowed!\n",
        "\n",
        "<span style=\"color:#d95c4c\">**IMPORTANT:**</span> Please, change the name of your submission file so that it contains your student ID!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8a2I9lNO0pf"
      },
      "source": [
        "In this assignment, we will take a closer look at some famous vision architectures.\n",
        "Since most of these architectures are very large, it requires high-end hardware to train from scratch.\n",
        "To leverage the limited availability of hardware, also *Transfer Learning* can be used.\n",
        "By using stored weights of a large network a new network can be trained cheaply on new datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xRQtBg3zO0pg",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import trange\n",
        "\n",
        "torch.manual_seed(1806)\n",
        "torch.cuda.manual_seed(1806)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTG9l1Y2O0ph",
        "outputId": "98a22aaa-b176-4cc5-8bc5-a3f64ba7c258",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "gdrive/MyDrive/.pytorch\n"
          ]
        }
      ],
      "source": [
        "# google colab data management\n",
        "import os.path\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    _home = 'gdrive/MyDrive/'\n",
        "except ImportError:\n",
        "    _home = '~'\n",
        "finally:\n",
        "    data_root = os.path.join(_home, '.pytorch')\n",
        "\n",
        "print(data_root)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyPk35LXO0pi",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## LeNet-5 and its Offspring\n",
        "\n",
        "![LeNet-5 architecture](https://miro.medium.com/max/2154/1*1TI1aGBZ4dybR6__DI9dzA.png)\n",
        "\n",
        "The LeNet-5 architecture (depicted above) is one of the first convolutional networks.\n",
        "Since convolutions are extremely well suited for many computer vision tasks,\n",
        "a wide variety of network architectures using convolutional layers has become available.\n",
        "Although the differences in performance are sometimes large,\n",
        "the architectures can generally be considered variations on the same theme."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjqFAVXyO0pi",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Alexnet\n",
        "\n",
        "![alex-net architecture](https://cdn-images-1.medium.com/max/1000/1*wzflNwJw9QkjWWvTosXhNw.png)\n",
        "\n",
        "In 2012 Alex Krizhevsky et al. won the [Imagenet Large Scale Visual Recognition Challenge](http://www.image-net.org/challenges/LSVRC/) (ILSVRC).\n",
        "The network they used, which is known as *Alex-net*, is depicted below and follows the same basic principles as LeNet-5.\n",
        "Alex-net has quite a bit more parameters than LeNet-5, therefore it requires a large amount of computational resources to train.\n",
        "\n",
        "To speed up training time, Alex-net was trained on GPU.\n",
        "Since GPUs have access to little memory compared to CPUs (especially back in the days),\n",
        "alex-net did not fit on a single GPU and required 2 GPUs to train the model,\n",
        "hence the distinction between two paths in the illustration of the network.\n",
        "\n",
        "On modern GPUs, it is no longer a problem to fit alex-net on a single GPU.\n",
        "Due to the fact that deep learning frameworks mostly support hardware acceleration,\n",
        "it has even become extremely easy and almost common to train (large) networks on GPUs.\n",
        "A more detailed description on how to achieve this in pytorch, is given below.\n",
        "\n",
        "Another important add-on, is the use of the dropout regularisation technique in the fully connected layers.\n",
        "From DL & NN 1 you should remember that dropout behaves differently during testing and training.\n",
        "When using Dropout or other modules with different behaviour, e.g. BatchNorm, in pytorch,\n",
        "it is important to make sure that your network operates in the right mode.\n",
        "To do this, the `nn.Module` class provides the `train` and `eval` methods\n",
        "and invokes it on all submodules to assure that the desired behaviour is triggered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StaQS7nRO0pj",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Pytorch GPU acceleration\n",
        "\n",
        "In pytorch, training a model on GPU is relatively easy.\n",
        "To copy a tensor `x` from main memory (or wherever it may be) to GPU memory,\n",
        "all we need to do is call `x.to('cuda')` or equivalently `x.cuda()`.\n",
        "When multiple GPUs are available, `x.to('cuda:0')` copies a tensor to the first GPU,\n",
        "`x.to('cuda:1')` to the second, etc.\n",
        "Similarly, to copy a tensor from a GPU (or again wherever it may be) to main memory,\n",
        "`x.to('cpu')` or equivalently `x.cpu()` can be used.\n",
        "\n",
        "Whenever a computation is done on tensors that reside on a specific device,\n",
        "the result will also be on that device.\n",
        "It is not possible, however, to make computations with tensors from different devices.\n",
        "This means that the training of an entire network automatically takes place on e.g. a GPU,\n",
        "as soon as all the variables reside on the same device.\n",
        "When working with neural networks,\n",
        "this is the case if both the network parameters and the data are moved to the same device.\n",
        "\n",
        "To move all parameters of a network to the correct device,\n",
        "The `nn.Module` class provides a convenience `to` method\n",
        "that moves all registered parameters, buffers and submodules to the correct device.\n",
        "\n",
        "As for the data, it is often possible to fit the entire dataset in GPU memory.\n",
        "However, often it does not provide any advantages or it even comes with disadvantages.\n",
        "E.g. the `MNIST` dataset from `torchvision` provides PIL images that can not reside on GPU.\n",
        "If the dataset would be stored on the GPU, the data would have to move to CPU first,\n",
        "where the pre-processing is done on the PIL images, and then move back to the GPU.\n",
        "Therefore, it is considered good practice to keep the dataset in main memory\n",
        "and move the samples to the GPU only when they are needed for computation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qElplMVpO0pk"
      },
      "source": [
        "### Exercise 1: Hardware Acceleration (3 points)\n",
        "\n",
        "In order to allow our computations to be accelerated,\n",
        "the utility functions `evaluate` and `update` require some minor adjustments.\n",
        "\n",
        " > Alter the `evaluate` and `update` functions from assignment 1\n",
        " > so that it is assured that the inputs are on the same device as the network parameters.\n",
        " > Also put the networks in the right modes so that dropout etc. work correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "deletable": false,
        "id": "tNCp3j6sO0pk",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "294592f974346dcdcff31010403bea51",
          "grade": false,
          "grade_id": "cell-56b6cb01eff2e2f8",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(network: nn.Module, data: DataLoader, metric: callable) -> list:\n",
        "    results = []\n",
        "    network = network.to('cuda')\n",
        "    for x, y in data:\n",
        "        x = x.to('cuda')\n",
        "        y = y.to('cuda')\n",
        "        logits = network(x)\n",
        "        res = metric(logits, y)\n",
        "        results.append(res.item())\n",
        "    return results\n",
        "\n",
        "\n",
        "@torch.enable_grad()\n",
        "def update(network: nn.Module, data: DataLoader, loss: nn.Module,\n",
        "           opt: optim.Optimizer) -> list:\n",
        "    network = network.to('cuda')\n",
        "    errs = []\n",
        "    for x, y in data:\n",
        "        x = x.to('cuda')\n",
        "        y = y.to('cuda')\n",
        "        logits = network(x)\n",
        "        err = loss(logits, y)\n",
        "        errs.append(err.item())\n",
        "        opt.zero_grad()\n",
        "        err.backward()\n",
        "        opt.step()\n",
        "    return errs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UfH_e3WOO0pl"
      },
      "outputs": [],
      "source": [
        "# sanity check\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "x_data = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0], [7.0, 8.0]])\n",
        "y_data = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
        "dataset = torch.utils.data.TensorDataset(x_data, y_data)\n",
        "data_loader = torch.utils.data.DataLoader(dataset, shuffle=True)\n",
        "model = SimpleModel()\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "errs = update(model, data_loader, loss_fn, optimizer)\n",
        "eval_errs = evaluate(model, data_loader, loss_fn)\n",
        "assert len(errs) == 4; assert len(eval_errs) == 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3RMYNL9GO0pm",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# sanity check\n",
        "class HackyLoss(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.devices = []\n",
        "\n",
        "    def forward(self, logits, y):\n",
        "        self.devices.append(logits.device)\n",
        "        return torch.nn.functional.cross_entropy(logits, y)\n",
        "\n",
        "\n",
        "test_net = nn.Linear(512, 10).train().to(\"cpu\")\n",
        "test_data = torch.utils.data.TensorDataset(\n",
        "    torch.randn(1, 512), torch.randint(10, size=(1, ))\n",
        ")\n",
        "test_loss = HackyLoss()\n",
        "\n",
        "test_loss.devices = []\n",
        "test_net.to(\"cuda\")\n",
        "try:\n",
        "    evaluate(test_net, DataLoader(test_data), test_loss)\n",
        "except RuntimeError:\n",
        "    pass\n",
        "\n",
        "assert len(test_loss.devices) > 0, (\n",
        "    \"ex1: evaluate function does not work on cuda device\"\n",
        ")\n",
        "assert all(dev.type == \"cuda\" for dev in test_loss.devices), (\n",
        "    \"ex1: evaluate function does not use cuda device\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "LoGW6M6qO0pn",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a4d2f024315ea088f618a37b3da16048",
          "grade": true,
          "grade_id": "cell-68e5207f6414f630",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "uyuvGuJdO0pn",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b2a4b11f16adcb1c43cc711f8ac88ee0",
          "grade": true,
          "grade_id": "cell-1000f2964ec27880",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "oxOhcNWtO0po",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2293eae5ca745c73874dab88fca3031e",
          "grade": true,
          "grade_id": "cell-0aeb6bf66633d859",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "8efrEZaIO0pp",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d5764e079dd2d9260aabe6c57db5e679",
          "grade": true,
          "grade_id": "cell-206c9dd0aacf2fe9",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "vevJJMU-O0pq",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7b2ac4d625468db6922bb3802981ce14",
          "grade": true,
          "grade_id": "cell-ae0a1be36ea30379",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "gFZtMessO0pq",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "80fc26e91bacb01faae0017730f34313",
          "grade": true,
          "grade_id": "cell-97ecdf4b2088e5d1",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8Mu9dXnO0pr",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### VGG\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/2628/1*lZTWFT36PXsZZK3HjZ3jFQ.png\"\n",
        "     alt=\"VGG architecture\" style=\"width: 70%; margin: auto\" />\n",
        "\n",
        "The Visual Geometry Group at Oxford University introduced\n",
        "different versions of architectures that are now known as VGG net.\n",
        "11-layer, 16-layer and 19-layer variants exist,\n",
        "all of which use only 3x3 convolutions in the feature extraction part.\n",
        "\n",
        "After winning the Imagenet Large Scale Visual Recognition Challenge (ILSVRC) in 2014,\n",
        "the weights of the winning models were made [available](https://www.robots.ox.ac.uk/~vgg/research/very_deep/).\n",
        "This made it possible for researchers with lower computational budgets\n",
        "to make use of the features the network has extracted for natural images.\n",
        "Since 2021, large pre-trained models often end up serving as [foundation models](https://en.wikipedia.org/wiki/Foundation_models).\n",
        "Note that VGG is a very small model compared to modern \"large\" models today."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UGZRdj2O0pr",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Exercise 2: VGG for CIFAR-10 (2 points)\n",
        "\n",
        "Most vision architectures have been trained on the ImageNet dataset, which is hard to come by:\n",
        "it is very large (a few 100GB) and requires registration to get access to the images.\n",
        "[CIFAR-10 and CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "are similar datasets that are much easier to obtain\n",
        "and they are one of the standard datasets in `torchvision.datasets`.\n",
        "In this exercise the goal is to modify a vision network that was trained on ImageNet\n",
        "to make predictions on CIFAR-10 so that we can reuse large parts of the weights.\n",
        "\n",
        " > Create a network with the same feature extraction architecture as\n",
        " > `torchvision.models.VGG` so that it can be used for CIFAR images.\n",
        " > Concretely, the goal is to replace the classifier to predict CIFAR labels\n",
        " > instead of the Imagenet labels.\n",
        " > Use global average pooling to make the classifier independent of the exact image size.\n",
        " > Keep the classifier architecture rectangular, i.e. same width for all layers (except for the classes).\n",
        "\n",
        "**Hint:** Take a look at [`torchvision.models.VGG`](https://pytorch.org/vision/0.13/_modules/torchvision/models/vgg.html) if you need some inspiration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "deletable": false,
        "id": "GO6XwRavO0ps",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ed7a1de69c060df6ec1967e80e1cae88",
          "grade": false,
          "grade_id": "cell-6028296fe7ae4ae8",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class CifarVGG(nn.Module):\n",
        "    \"\"\" Variant of the VGG network for classifying CIFAR images. \"\"\"\n",
        "\n",
        "    def __init__(self, features: nn.Module, num_classes: int = 10):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        features : nn.Module\n",
        "            The convolutional part of the VGG network.\n",
        "        num_classes : int\n",
        "            The number of output classes in the data.\n",
        "        \"\"\"\n",
        "        # YOUR CODE HERE\n",
        "        super(CifarVGG, self).__init__()\n",
        "        self.features = features\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 512),   # Dimensions from torchvision.models.vgg (4096)\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QguRHN9rO0ps"
      },
      "outputs": [],
      "source": [
        "# sanity check\n",
        "test_net = CifarVGG(nn.Identity()).eval().requires_grad_(False)\n",
        "try:\n",
        "    ref = test_net(torch.zeros(1, 512, 7, 7))\n",
        "except RuntimeError:\n",
        "    raise AssertionError(\"ex2: classifier does not seem to work with default image sizes\") from None\n",
        "\n",
        "assert torch.all(test_net(torch.zeros(1, 512, 14, 14)) == ref), (\n",
        "    \"ex2: architecture depends on input image size, did you forget global average pooling?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "LzDWv2LxO0pt",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9ee5a85203d0529ae957b94c03e5ff0e",
          "grade": true,
          "grade_id": "cell-2e8e3ccf1456fef0",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "EJH-7X0BO0pt",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "039d917d553a4f4068985f8660a949a2",
          "grade": true,
          "grade_id": "cell-8e61a71202179ddd",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "C7WqblGAO0pu",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "73126064e438869c2f70633c1419cbe7",
          "grade": true,
          "grade_id": "cell-df16e66fb7e6d477",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-CGaVeIO0pu",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Exercise 3: Existing Features (2 points)\n",
        "\n",
        "Training a network like VGG (or any of the other networks in this assignment)\n",
        "can take a few hours when training on a GPU.\n",
        "Therefore it is often useful to be able to load pre-trained weights into the network.\n",
        "Also, saving a model that has been trained for hours can often save a lot of time.\n",
        "In pytorch this is possible through what is called\n",
        "[`state_dict`s](https://pytorch.org/tutorials/beginner/saving_loading_models.html).\n",
        "Saving the parameters of a pytorch module can be done with `torch.save(module.state_dict(), path)`,\n",
        "whereas loading saved parameters is done with `module.load_state_dict(torch.load(path))`.\n",
        "\n",
        " > Write a function `vgg_init_` to initialise a `CifarVGG` network.\n",
        " > It should load the pre-trained weights for the **11-layer variant of VGG** from `torchvision.models.vgg`\n",
        " > to initialise the feature extractor of the model\n",
        " > and reasonably initialise the classifier using initialisation functions from `torch.nn.init`.\n",
        "\n",
        "**Hint:** you can use all of the functions available in `torchvision.models.vgg`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "deletable": false,
        "id": "00881GydO0pv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "afc920e40ccd329d5a059d8bb888d1fb",
          "grade": false,
          "grade_id": "cell-3f81b88fa13d2110",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def vgg_init_(network: CifarVGG):\n",
        "    \"\"\"\n",
        "    Initialise a CifarVGG network with a pre-trained VGG feature extractor.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    network : CifarVGG\n",
        "        The model to initialise.\n",
        "    \"\"\"\n",
        "    from torchvision.models import vgg\n",
        "    # YOUR CODE HERE\n",
        "    vgg_model = vgg.vgg11(pretrained = True)\n",
        "    vgg_model.features.load_state_dict(vgg_model.features.state_dict())\n",
        "\n",
        "    #initialize the params for the network\n",
        "    for module in network.modules():\n",
        "        if isinstance(module, nn.Linear):\n",
        "          nn.init.kaiming_normal_(module.weight, mode = 'fan_out', nonlinearity='relu')\n",
        "          if module.bias is not None:     #initialize bias if model has one\n",
        "            nn.init.zeros_(module.bias)\n",
        "    return network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DIpeMpSO0pv",
        "outputId": "a5e8d8b6-ccc3-48b2-be04-90e3d7289627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg11-8a719046.pth\" to /root/.cache/torch/hub/checkpoints/vgg11-8a719046.pth\n",
            "100%|██████████| 507M/507M [00:03<00:00, 168MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CifarVGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (14): ReLU(inplace=True)\n",
              "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=512, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# sanity check\n",
        "vgg11 = torchvision.models.vgg11()\n",
        "network = CifarVGG(vgg11.features, num_classes=10)\n",
        "vgg_init_(network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "d1hKtTnnO0pv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f56ff2dcb5f7d13605fc412af50a7c54",
          "grade": true,
          "grade_id": "cell-fa879703d117285d",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Qqo3tUYYO0pw",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ce0812b910f059f082b7d9e3af582aff",
          "grade": true,
          "grade_id": "cell-9c50af0b59b8a087",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Q5NyL_wQO0pw",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0a9ec2b82e5d48f1e2a48532b658a3d2",
          "grade": true,
          "grade_id": "cell-b68148f3f01652e8",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "i6kLi4pOO0px",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0a5583e9b43acd58346773a3274f0ec0",
          "grade": true,
          "grade_id": "cell-4b3c293bbf38506e",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QaA32coO0px",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Exercise 4: Training (part of) the Network (4 points)\n",
        "\n",
        "Obviously, a classifier for CIFAR 10 will be different from a classifier for Imagenet.\n",
        "With the initialisation above, the `CifarVGG` has a ready-to-go feature extractor,\n",
        "but the classifier part still has to be trained.\n",
        "To do this training efficiently, there are a few things left to do.\n",
        "\n",
        " > The code below should train the entire network on the entire dataset for a few epochs.\n",
        " > Modify the code so that\n",
        " > 1. it only trains the classifier part of the network using SGD\n",
        " > and leaves the convolutional feature extractor untouched, i.e., *frozen*.\n",
        " > 2. the 32x32 CIFAR images are upscaled to 224x224 pixels.\n",
        " > 3. training is done on the GPU, which is generally faster.\n",
        " > 4. it uses a parallel dataloader to make sure that the GPU does not have to wait for data.\n",
        " > 5. only a random subset of 500 images from the CIFAR data is used for training.\n",
        " > 6. a random subset of 500 images from the CIFAR data is used as validation data.\n",
        " > You will also need to include a round of validation in the training loop.\n",
        " > This should give you some confidence that the classifier is learning something useful.\n",
        "\n",
        "**Hint:** you might find useful tools under\n",
        "[`torch.utils.data`](https://pytorch.org/docs/stable/data.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "deletable": false,
        "id": "ZSwRCKqhO0py",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c7d9b8ac7c6f5b1492e2a78701d65852",
          "grade": false,
          "grade_id": "cell-a950b67112844019",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_cifar10(root: str, batch_size: int = 32, resize: tuple[int, int] = (224, 224),\n",
        "                num_train: int = 500, num_valid: int = 500, num_workers: int = 4):\n",
        "    \"\"\"\n",
        "    Get dataloader(s) for CIFAR-10.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    root : str\n",
        "        Path to directory where CIFAR-10 dataset is stored.\n",
        "    batch_size : int, optional\n",
        "        The number of samples per mini-batch.\n",
        "    resize : tuple of int, optional\n",
        "        Desired width and height of loaded images.\n",
        "    num_train : int, optional\n",
        "        Number of (random) samples to use for training.\n",
        "    num_valid : int, optional\n",
        "        Number of (random) samples to use for validation.\n",
        "    num_workers : int, optional\n",
        "        Number of parallel processes to use for loading data.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    train_batches : DataLoader\n",
        "        A dataloader that loads mini-batches of CIFAR-10 for training.\n",
        "    valid_batches : DataLoader\n",
        "        A dataloader that loads (mini-)batches of CIFAR-10 for validation.\n",
        "    \"\"\"\n",
        "    normalise=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
        "        torchvision.transforms.Resize(resize)   #resize the image\n",
        "    ])\n",
        "\n",
        "    cifar10 = torchvision.datasets.CIFAR10(root, transform=normalise, download=True)\n",
        "\n",
        "    train, valid, _ = torch.utils.data.random_split(cifar10, [num_train, num_valid, len(cifar10)-num_train-num_valid]) #split data in train and validation set\n",
        "    train_batches = DataLoader(train, batch_size=batch_size, num_workers=num_workers) # added num workers to make it parallel\n",
        "    valid_batches = DataLoader(valid, batch_size=batch_size, num_workers=num_workers)\n",
        "    return train_batches, valid_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "Ki3c0oM1O0pz",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fe0750552b41c1d939730be454011c6b",
          "grade": true,
          "grade_id": "cell-50a57b988de2456a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "292d1c8f-888c-4bc2-ed98-9803abb9dfd4",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Test Cell: do not edit or delete!\n",
        "train_batches, valid_batches = get_cifar10(data_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "n7qC6Hf9O0pz",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1e18a491116f79690e6a043788e21cc5",
          "grade": true,
          "grade_id": "cell-6eda307d38b80b9b",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "WgSylvdYO0p0",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "13d6fa98d1965a611e71cf8ad5407ae9",
          "grade": true,
          "grade_id": "cell-c0a34d1d729057c3",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "DcXDs2W-O0p0",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4920006b846ee083072432a5f538ea52",
          "grade": true,
          "grade_id": "cell-3c0f52576cde2785",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "deletable": false,
        "id": "z5cfFAuDO0p1",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "318f2e3f3ac0446dd97fdcdf35117d4e",
          "grade": false,
          "grade_id": "cell-38ebe178995403c2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_vgg(num_classes: int = 10, device: str = \"cpu\"):\n",
        "    \"\"\"\n",
        "    Create and initialise VGG network on given device.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_classes : int, optional\n",
        "        The number of output units for the network.\n",
        "    device : str, optional\n",
        "        A string representing the device to work on\n",
        "    \"\"\"\n",
        "    vgg11 = torchvision.models.vgg11()\n",
        "    net = CifarVGG(vgg11.features, num_classes=10)\n",
        "    net = vgg_init_(net)\n",
        "\n",
        "    for name, param in net.named_parameters():\n",
        "        if 'features' in name:\n",
        "          param.requires_grad = False           #freeze the conv weights\n",
        "    return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "e7VmFOMtO0p2",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cf747f572995d504cc9ecc86d6e7d314",
          "grade": true,
          "grade_id": "cell-54b052aa6ea81245",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!\n",
        "network = get_vgg(device='cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "deletable": false,
        "id": "j95YGmUcO0p2",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "011d4681e4ffbc5d5ca7dfb8a0295e88",
          "grade": false,
          "grade_id": "cell-9744d03f06fc1e80",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class TransferTrainer:\n",
        "\n",
        "    def __init__(self, model: nn.Module):\n",
        "        \"\"\"\n",
        "        Create a trainer for transfer learning.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        model : nn.Module\n",
        "            The model to train.\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.objective = nn.CrossEntropyLoss() #reduction=mean is default, with reduction sum I get vanishing gradients after a few iterations.\n",
        "        # YOUR CODE HERE\n",
        "        self.optimiser = optim.SGD(self.model.parameters(), lr=0.001)\n",
        "        self.model.to('cuda') #shift model to GPU\n",
        "\n",
        "\n",
        "    def train(self, train_batches: DataLoader, valid_batches: DataLoader,\n",
        "              num_epochs: int = 20):\n",
        "        \"\"\"\n",
        "        Train (part of) the network for a number of epochs.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        train_batches : DataLoader\n",
        "            The training data for updating the network.\n",
        "        valid_batches : DataLoader\n",
        "            The validation data for evaluating the network.\n",
        "        num_epochs : int, optional\n",
        "            The number of iterations over the training data.\n",
        "        \"\"\"\n",
        "        train_errs, valid_errs = [], []\n",
        "        for _ in trange(num_epochs):\n",
        "            self.model.train()\n",
        "            local_errs = update(self.model, train_batches, self.objective, self.optimiser)\n",
        "            train_errs.append(sum(local_errs) / len(local_errs) / train_batches.batch_size)\n",
        "\n",
        "            self.model.eval()\n",
        "            val_errs = evaluate(self.model, valid_batches, self.objective)\n",
        "            valid_errs.append(sum(val_errs) / len(val_errs) / train_batches.batch_size)\n",
        "        return train_errs, valid_errs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6c1e7d0e63144381b609ea4e153af65d",
            "ad16ad7d72e74471952835f3c10f0b87",
            "9d7e0973bad64f11a8ab2f7f9bb345c8",
            "2126c23153a9472b8eef8b9cbace99a5",
            "7ca1b679f30c402e85443f70a654d6d1",
            "b052e795d6d2495e9d8423106baa5392",
            "9d73cb96a0ee47679a3e143015435084",
            "35b62e1352c44ebfa1d0b201b14eb3b3",
            "d54d18b3abab408aa50bfccef95dbb8e",
            "e89f835efeb548bfa719f83fa138c519",
            "be5099a188364fd4b7929bba78e6eccd"
          ]
        },
        "id": "9V22tmsPO0p3",
        "outputId": "77f74189-91c7-4d9e-d089-a50d6d27f887",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c1e7d0e63144381b609ea4e153af65d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer = TransferTrainer(network)\n",
        "train_errs, valid_errs = trainer.train(train_batches, valid_batches, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "uyzls2xIO0p3",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cd7a0e7fb867ecdd95943d7e32f2d36d",
          "grade": true,
          "grade_id": "cell-d90bc7397e62537b",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "H58GzioyO0p4",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "29921949adf9c0894a0abcaf32d218e4",
          "grade": true,
          "grade_id": "cell-2d58a4e446f6eeb6",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "OW6A3fBGO0p4",
        "outputId": "54947c97-e17a-4b47-b90f-bacc4d766d60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ran on cuda:0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plot learning curves\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(range(1, len(train_errs) + 1), train_errs, label=\"train\")\n",
        "plt.plot(range(1, len(valid_errs) + 1), valid_errs, label=\"valid\")\n",
        "plt.legend()\n",
        "print(f\"ran on {next(network.parameters()).device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg8Y3D-aO0p4",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Skip-connections\n",
        "\n",
        "One of the most popular modern network architectures for vision is the residual network.\n",
        "The main feature of this architecture is the so-called skip-connection,\n",
        "which allows to combine the activations with the original inputs in each layer.\n",
        "Since these skip-connections open up a gradient highway,\n",
        "they make it possible to train much deeper networks than is possible without the skip-connections.\n",
        "\n",
        "Mathematically, the simplest form of a skip connection can be written as\n",
        "$$\\boldsymbol{s} = \\boldsymbol{x} + f(\\boldsymbol{x}).$$\n",
        "In order for this to work, the dimensions of $\\boldsymbol{x}$ and $f(\\boldsymbol{x})$ must line up.\n",
        "This means that in this formulation, only square layers,\n",
        "i.e. layers with the same number of inputs and outputs, are possible.\n",
        "\n",
        "In order to use a skip-connection on layers that reduce the dimensionality,\n",
        "a linear transform on $\\boldsymbol{x}$ can be inserted in the equation.\n",
        "Since also other operations are possible, on both inputs and (pre-)activations,\n",
        "we can generalise the skip-connection formula to\n",
        "$$\\boldsymbol{s} = \\boldsymbol{C} \\cdot \\boldsymbol{x} + \\boldsymbol{T} \\cdot f(\\boldsymbol{x}),$$\n",
        "where $\\boldsymbol{C}$ and $\\boldsymbol{T}$ are linear transformations (a.k.a. matrices)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdmQbuRuO0p5"
      },
      "source": [
        "### Exercise 5: Pre-Residual Networks (4 points)\n",
        "\n",
        "The original and most commonly used residual networks actually do not implement skip connections as in the formula above.\n",
        "Upon closer inspection (e.g. `torchvision.models.resnet`), it becomes clear that the most famous skip-connection looks more like\n",
        "\n",
        "$$\\boldsymbol{a} = \\phi(\\boldsymbol{x} + f(\\boldsymbol{x})),$$\n",
        "\n",
        "where $\\phi$ is some non-linear activation function.\n",
        "This non-linearity typically interferes with the signal propagation of the network.\n",
        "As a result, gradients might still vanish despite the skip-connection.\n",
        "\n",
        "Pre-Residual Networks aim to counter this problem by moving skip-connections to the level of pre-activations, such that\n",
        "\n",
        "$$\\boldsymbol{a} = \\boldsymbol{x} + f(\\phi(\\boldsymbol{x})).$$\n",
        "\n",
        "This way, clean signal propagation can be guaranteed and learning should become easier.\n",
        "\n",
        " > Implement the `PreResBlock` class so that it can be used as a layer in a pre-residual network.\n",
        " > The residual part of the network, $f$, should be a small network with two convolutional layers.\n",
        " > Both layers should use the given `kernel_size` and preserve the image size if `stride` is one.\n",
        " > If `stride` is greater than one, the network should reduce the spatial dimensions by this factor.\n",
        " > Make sure that the network also works if `in_channels != out_channels` and `stride > 1`.\n",
        " > Try to avoid unnecessary parameters, especially for the skip-connection.\n",
        " > Precice information on the implementation of the `PreResBlock` can be found in this paper [Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "deletable": false,
        "id": "oiB1Pr_YO0p5",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ac8e641d2f59581656dea384274d4089",
          "grade": false,
          "grade_id": "cell-012fdda0f6fc954c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class PreResBlock(nn.Module):\n",
        "    \"\"\" Residual block using skip-connections on pre-activation level. \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int = 3,\n",
        "                 stride: int = 1, phi: nn.Module = nn.ReLU(), extra_pars: bool = True):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        in_channels : int\n",
        "            Number of input channels.\n",
        "        out_channels : int\n",
        "            Number of output channels.\n",
        "        kernel_size : int\n",
        "            Size of the kernel in all dimensions.\n",
        "        stride : int\n",
        "            Factor by which to reduce the spatial dimensions.\n",
        "        phi : nn.Module\n",
        "            The activation function to use in the residual branch.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding = kernel_size//2)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride = 1, padding = kernel_size//2)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride = stride, padding = 0)\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "\n",
        "        self.phi = phi\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_phi = self.phi(x)\n",
        "\n",
        "        a = self.conv1(x_phi)\n",
        "        a = self.batch_norm1(a)\n",
        "        a = self.phi(a)\n",
        "        a = self.conv2(a)\n",
        "        a = self.batch_norm2(a)\n",
        "\n",
        "        #skip connection\n",
        "        skip = self.shortcut(x)\n",
        "\n",
        "        return a + skip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "ugQ5WpyMO0p5",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c1262266d09ae05c7e69c639eaa6444e",
          "grade": true,
          "grade_id": "cell-6ad2bd0b1b1d2a9c",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "664611de-49c4-4186-958d-f266cb216a3a",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, torch.Size([1, 8, 32, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Test Cell: do not edit or delete!\n",
        "block = PreResBlock(8, 8)\n",
        "out = block(torch.zeros(1, 8, 32, 32))\n",
        "sum(par.numel() for par in block.parameters()), out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "YaoP0FpEO0p6",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bc3cf926bc0e264cd47c32871c9459fc",
          "grade": true,
          "grade_id": "cell-f1f85167e93e44c3",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99cd13c8-5010-43a5-df0d-ddc8e5a157ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1272, torch.Size([1, 8, 16, 16]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Test Cell: do not edit or delete!\n",
        "strided_block = PreResBlock(8, 8, stride=2)\n",
        "out = strided_block(torch.zeros(1, 8, 32, 32))\n",
        "sum(par.numel() for par in strided_block.parameters()), out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "DRCOakUIO0p6",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "78b578fb34c5b7846fcb1f0c00f187a7",
          "grade": true,
          "grade_id": "cell-3ac75a0d02d17fd3",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "iBesBMZZO0p6",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1ceed3d0a542f69db6c6b2860cddb14e",
          "grade": true,
          "grade_id": "cell-663c81b961940982",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "pGESDcJkO0p6",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7c6e53e06430c37e13f80289415565da",
          "grade": true,
          "grade_id": "cell-59ae8844ab4b4070",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "W4WSZ7HkO0p7",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ec2e33275158974903fce00c4bb90a95",
          "grade": true,
          "grade_id": "cell-167a0183735eef85",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "tDXKr2IFO0p7",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b1042058baed7c3c7d8a56497d3de570",
          "grade": true,
          "grade_id": "cell-710621dae0591506",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "SIK5zVuYO0p7",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "97b6fb54abbc54f70c235443eff1e317",
          "grade": true,
          "grade_id": "cell-57776f082e9e6e4a",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "fBqtTNxnO0p8",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "aeea2e9ef0bb2c47f167f975bdc7c3ef",
          "grade": true,
          "grade_id": "cell-54f1a5309ea73174",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRTtCYKQO0p8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c1e7d0e63144381b609ea4e153af65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad16ad7d72e74471952835f3c10f0b87",
              "IPY_MODEL_9d7e0973bad64f11a8ab2f7f9bb345c8",
              "IPY_MODEL_2126c23153a9472b8eef8b9cbace99a5"
            ],
            "layout": "IPY_MODEL_7ca1b679f30c402e85443f70a654d6d1"
          }
        },
        "ad16ad7d72e74471952835f3c10f0b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b052e795d6d2495e9d8423106baa5392",
            "placeholder": "​",
            "style": "IPY_MODEL_9d73cb96a0ee47679a3e143015435084",
            "value": "100%"
          }
        },
        "9d7e0973bad64f11a8ab2f7f9bb345c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35b62e1352c44ebfa1d0b201b14eb3b3",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d54d18b3abab408aa50bfccef95dbb8e",
            "value": 20
          }
        },
        "2126c23153a9472b8eef8b9cbace99a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e89f835efeb548bfa719f83fa138c519",
            "placeholder": "​",
            "style": "IPY_MODEL_be5099a188364fd4b7929bba78e6eccd",
            "value": " 20/20 [01:21&lt;00:00,  3.90s/it]"
          }
        },
        "7ca1b679f30c402e85443f70a654d6d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b052e795d6d2495e9d8423106baa5392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d73cb96a0ee47679a3e143015435084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35b62e1352c44ebfa1d0b201b14eb3b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d54d18b3abab408aa50bfccef95dbb8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e89f835efeb548bfa719f83fa138c519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be5099a188364fd4b7929bba78e6eccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}