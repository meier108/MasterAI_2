{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec806f87",
   "metadata": {},
   "source": [
    "# Assignment 3: Variational Autoencoders\n",
    "\n",
    "*Author:* Thomas Adler / Eric Volkmann\n",
    "\n",
    "*Copyright statement:* This  material,  no  matter  whether  in  printed  or  electronic  form,  may  be  used  for  personal  and non-commercial educational use only.  Any reproduction of this manuscript, no matter whether as a whole or in parts, no matter whether in printed or in electronic form, requires explicit prior acceptance of the authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c42f66-28bd-4ce2-8e50-2084b4fea5e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0bb224",
   "metadata": {},
   "source": [
    "### Exercise 1: Derivation of ELBO (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc030daa-8283-491a-9144-2624d77c9670",
   "metadata": {},
   "source": [
    "Prove the evidence lower bound (ELBO), which states that \n",
    "\\begin{align*}\n",
    "    \\mathbb E_{q(z \\mid x)}[\\log \\frac{p(x, z)}{q(z \\mid x)}] \\leq \\log p(x),\n",
    "\\end{align*}\n",
    "for some distributions $q(z \\mid x), p(x, z), p(x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7af5b4c",
   "metadata": {},
   "source": [
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa6566",
   "metadata": {},
   "source": [
    "### Exercise 2: Decomposition of ELBO (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65caa134-7d0a-40b4-baa4-470a0eb7de9f",
   "metadata": {},
   "source": [
    "We have the observable variable $x$ and the latent variable $z$. \n",
    "We can observe $x$ only through a dataset $\\mathcal D$. \n",
    "For $z$, we choose the prior $p(z) = \\mathcal N(0, 1)$ and the posterior (or encoder) distribution $q(z \\mid x) = \\mathcal N(\\mu(x), \\sigma^2(x))$, where $\\mu(x)$ and $\\sigma^2(x)$ are neural networks with shared parameters, i.e., $(\\mu(x), \\sigma^2(x)) = \\text{encode}(x)$. \n",
    "This makes $q(z \\mid x)$ easy to sample from. \n",
    "Subsequently, we can use the decoder $p(x \\mid z)$ to reconstruct $x$. \n",
    "\n",
    "There are several interpretations as to why the maximization of the ELBO is a suitable objective for VAEs. \n",
    "To obtain one of them, prove the following identity \n",
    "\\begin{align*}\n",
    "    \\mathbb E_{q(z \\mid x)}[\\log \\frac{p(x, z)}{q(z \\mid x)}] = \\mathbb E_{q(z \\mid x)}[\\log p(x \\mid z)] - D_{\\text{KL}}(q(z \\mid x) \\mathbin{||} p(z))\n",
    "\\end{align*}\n",
    "where $D_{\\text{KL}}$ denotes the Kullback-Leibler divergence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2842731",
   "metadata": {},
   "source": [
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae65caf",
   "metadata": {},
   "source": [
    "### Exercise 3: Reconstruction Term (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db37fc2-04c3-4a5e-97e0-dbec3d796aee",
   "metadata": {},
   "source": [
    "The first term on the right-hand side of above equation is called the *reconstruction term*. \n",
    "To see why, analyze it under the expectation over $x$. \n",
    "To be more clear, let us denote the reconstruction of $x$ by the VAE as $\\tilde x$. \n",
    "Prove the identity\n",
    "\\begin{align*}\n",
    "    \\mathbb{E}_{p(x)} [\\mathbb{E}_{q(z \\mid x)}[\\log p(\\tilde x \\mid z)]] = - \\mathcal H(p(x \\mid z)) - \\mathbb E_{p(z)}[D_{\\text{KL}}(p(x \\mid z) \\mathbin{||} p(\\tilde x \\mid z)))].\n",
    "\\end{align*}\n",
    "Which effects does the maximization of the reconstruction term have on the different parts of the VAE?\n",
    "That is, interpret the two terms on the right-hand side in the context of VAE training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c571e",
   "metadata": {},
   "source": [
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13396d4d",
   "metadata": {},
   "source": [
    "### Exercise 4: Regularization Term (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d952ab7-56c4-40a6-87b8-2475a9090d0d",
   "metadata": {},
   "source": [
    "The second term of the decomposition of the ELBO is a regularization term. \n",
    "Again, we analyze it under the expectation over $x$. \n",
    "Prove that \n",
    "\\begin{align*}\n",
    "    \\mathbb E_{p(x)}[D_{\\text{KL}}(q(z \\mid x) \\mathbin{||} p(z))] = I(x, z),\n",
    "\\end{align*}\n",
    "where $I(\\cdot, \\cdot)$ denotes mutual information. \n",
    "For each side of this identity, give a different interpretation of the imposed regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1def3662",
   "metadata": {},
   "source": [
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc9b7ac",
   "metadata": {},
   "source": [
    "### Exercise 5: Derivation of Decoder Loss Function (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a173a623-2b9a-455f-9951-4dfc037b7835",
   "metadata": {},
   "source": [
    "Our considerations of the ELBO so far were somewhat abstract. \n",
    "In this exercise we will derive a concrete loss function that is ready for implementation. \n",
    "To this end, revisit the decomposition of the ELBO from exercise 2. \n",
    "We will use a softmax function on the decoder output to parameterize $p(x \\mid z)$ as a categorical distribution with $k$ categories. \n",
    "We denote the softmax-activated decoder output as $\\sigma(z)_i, i \\in \\{1, \\dots, k\\}$. \n",
    "Prove that under these assumptions \n",
    "\\begin{align*}\n",
    "    \\log p(x \\mid z) = x \\log \\sigma(z)_x.\n",
    "\\end{align*}\n",
    "How do we obtain the expectation under $q(z \\mid x)$?\n",
    "Note that in practice $x$ will be a vector and we will use \n",
    "\\begin{align*}\n",
    "    \\log p(x_1, \\dots, x_d \\mid z) = \\sum_{j=1}^d x_j \\log \\sigma(z)_{x_j}.\n",
    "\\end{align*}\n",
    "Which assumption is implied in this identity? \n",
    "Is it justified?\n",
    "\n",
    "Since we maximize the ELBO, our loss function will be \n",
    "\\begin{align*}\n",
    "    \\mathcal L_{\\text{decoder}} = -\\sum_{j=1}^d x_j \\log \\sigma(z)_{x_j}.\n",
    "\\end{align*}\n",
    "Thus, we can just use the familiar cross-entropy loss function. \n",
    "\n",
    "*Note that we used $\\sigma^2(x)$ as one of the outputs of the encoder. Here, $\\sigma(x)$ denotes the softmax-activated decoder output. So you should read the square more as a part of the name than an operation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8be763",
   "metadata": {},
   "source": [
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60405dbc",
   "metadata": {},
   "source": [
    "### Exercise 6: Derivation of Encoder Loss Function (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918e4e35-0768-4d09-90ab-6fe5ccc14c26",
   "metadata": {},
   "source": [
    "Prove that the encoder loss function derived from the ELBO is \n",
    "\\begin{align*}\n",
    "    \\mathcal L_{encoder} = D_{\\text{KL}}(q(z \\mid x) \\mathbin{||} p(z)) = \\frac12 (\\mu^2(x) + \\sigma^2(x) - \\log \\sigma^2(x) - 1).\n",
    "\\end{align*}\n",
    "Interpret this result. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e012e",
   "metadata": {},
   "source": [
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e608069",
   "metadata": {},
   "source": [
    "### Exercise 7: Reparametrization Trick (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988bee51-c595-44b0-9435-37275379db60",
   "metadata": {},
   "source": [
    "We are almost ready to implement our VAE. \n",
    "There remains only one small problem to solve. \n",
    "That is, passing down gradients from the decoder to the encoder is not possible due to the sampling step between them, i.e., drawing $z \\sim \\mathcal N(\\mu(x), \\sigma^2(x))$. \n",
    "This sampling step introduces a discontinuity which we cannot differentiate. \n",
    "Luckily, there is a simple solution for that. \n",
    "We sample a different random variable $\\varepsilon \\sim \\mathcal N(0, 1)$ and define $z = g(\\varepsilon, \\mu(x), \\sigma^2(x))$ via a deterministic function $g$. \n",
    "This is known as the *reparameterization trick*. \n",
    "What form must $g$ have? \n",
    "How does it resolve the discontinuity problem? \n",
    "Argue why $g(\\varepsilon, \\mu(x), \\sigma^2(x))$ and $\\varepsilon$ have the same distribution only with different moments. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e842d6a8",
   "metadata": {},
   "source": [
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3bc328-15ab-403f-8850-55989e08d375",
   "metadata": {},
   "source": [
    "## Implementation and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca29df4",
   "metadata": {},
   "source": [
    "### Exercise 8: VAE Training (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b69f915-e731-4fc0-9a15-41d76e41ff5b",
   "metadata": {},
   "source": [
    "Below you find a basic autoencoder architecture and a MNIST dataloader. \n",
    "Implement the forward passes and a training loop that features the reparametrization trick and maximizes the ELBO as derived in the previous exercises. \n",
    "Visualize the training progress. \n",
    "\n",
    "You can then try to modify the architecture (e.g. CNN-based architecture, different activation functions, residual connections,...) or the training loop (weighting of loss terms, weight decay, gradient clipping...) to improve the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7733c114-3439-477e-b49a-867f7a0cca43",
   "metadata": {},
   "source": [
    "If you want to try a latent dim > 1, you can assume for a multivariate gaussian  the KL-Divergence has this simple form\n",
    "\n",
    "$D_{KL}(\\mathcal{N}(\\mu, \\exp( I \\sigma^2))) || \\mathcal{N}(0, 1)) = \\frac{1}{2} \\sum_{j=1}^{latent\\_dim} (\\sigma_j^2 + \\mu_j^2 - 1 - \\log(\\sigma_j^2))$\n",
    "\n",
    "However, in modern PyTorch it is recommended to use `torch.distributions.kl.kl_divergence()`, check out https://pytorch.org/docs/stable/distributions.html\n",
    "\n",
    "You can initialize a `torch.distribution` and use `.rsample()`, which is the reparametrization trick built-in to PyTorch.\n",
    "\n",
    "*Hint: You can you these features to also use gaussian which have a more complicated covariance matrix than $I \\sigma^2$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a65ea554-b56f-4dc8-abaa-8eecefa25107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmlarchive.com%2Fwp-content%2Fuploads%2F2022%2F09%2FNew-Project-3.png&f=1&nofb=1&ipt=c92212efee02295a5612e1ef0639d4ceb260a7d293579a10afdacb4cd55e27ef&ipo=images\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmlarchive.com%2Fwp-content%2Fuploads%2F2022%2F09%2FNew-Project-3.png&f=1&nofb=1&ipt=c92212efee02295a5612e1ef0639d4ceb260a7d293579a10afdacb4cd55e27ef&ipo=images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84acf67f-d957-4c35-8ec1-f8f8b9e16fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from itertools import chain\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93df6094-9f80-43ee-90b1-4c54348a36e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0e331f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, eta):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 4, hidden_dim // 8),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 8, latent_dim), # 2 for mean and variance.\n",
    "        )\n",
    "        self.eta = eta ## Hint: add eta to the variance predictions for numerical stability\n",
    "        self.latent_dim = 2\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        ########## YOUR SOLUTION HERE ##########\n",
    "        \n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 8),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 8, hidden_dim // 4),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 4, hidden_dim // 2),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        ########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bd0a1eb-69c1-4b58-87aa-d019076e48b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(420)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-2\n",
    "num_epochs = 10\n",
    "eta = 1e-9\n",
    "\n",
    "optimizer_class = torch.optim.AdamW #You can try out different optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13162bfc-9802-4071-8c3e-69e73e94d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4adc420",
   "metadata": {},
   "source": [
    "### Exercise 9: VAE Inference (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee95da0a-e6f6-44eb-a827-cc7133dd95d7",
   "metadata": {},
   "source": [
    "- Compute the test loss\n",
    "- Visualize some reconstruction examples from both training and test set. \n",
    "- Generate new samples: Since the latent variables $z$ have the simple distribution $\\mathcal N(0, I)$, we can easily generate new samples from the training distribution by sampling $z$ and feeding it to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d84a026d-aab5-4a0c-918f-8c0d5f88a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(ax, img):\n",
    "    img = img / 2 + 0.5 # img in [-1, 1]\n",
    "    ax.imshow(img.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e67a4f00-3906-44c0-8122-26cde04473fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute test error\n",
    "encoder.train(False)\n",
    "decoder.train(False)\n",
    "running_loss = 0\n",
    "running_recon = 0\n",
    "running_kld = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a1b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824be3ee-0c84-435c-af76-42c83f2d6249",
   "metadata": {},
   "source": [
    "### Bonus Exercise: Visualization (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8cada5-0c12-4b8c-acdb-285f86f9a3ee",
   "metadata": {},
   "source": [
    "Try to visualize the distribution of the encoded latents of the test set. One possibility is to use a scatter plot and color the points according to their label.\n",
    "\n",
    "Next, try to interpolate in the latent space. Can you generate smooth transitions between the digits? \n",
    "Discuss your results! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b7674f-9e5b-4f13-9793-a6857c70ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## YOUR SOLUTION HERE ##########"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
